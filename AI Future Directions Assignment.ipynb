{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1ef33f-8baf-4e1b-98f8-b27a49d984c2",
   "metadata": {},
   "source": [
    "# Part 2: Practical Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d16825-12d1-412a-9ab6-8e39f8aea886",
   "metadata": {},
   "source": [
    "## Task 1: Edge AI Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d6a562-e95d-4939-ab70-462447bca22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a6201fa-3cca-4e10-9663-a762f389b28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "Creating simple dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Set random seed for reproducible results\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Creating simple dataset...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbf3d35-82ea-4789-9aeb-b8428d9f4234",
   "metadata": {},
   "source": [
    "## Create Simple Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ceabf03-123f-4a0f-898d-3964313ebfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 250\n",
      "Test samples: 50\n",
      "Image size: (64, 64, 3)\n",
      "Classes: ['plastic', 'paper', 'glass', 'metal', 'organic']\n"
     ]
    }
   ],
   "source": [
    "# 5 types of recyclable items\n",
    "class_names = ['plastic', 'paper', 'glass', 'metal', 'organic']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Create simple synthetic data\n",
    "def create_simple_dataset():\n",
    "    # Small dataset for quick training\n",
    "    samples_per_class = 50  # Small for quick demo\n",
    "    img_size = 64  # Smaller images for faster processing\n",
    "    \n",
    "    # Training data\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    # Test data  \n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    for class_id, class_name in enumerate(class_names):\n",
    "        # Training samples\n",
    "        for i in range(samples_per_class):\n",
    "            # Create unique pattern for each class\n",
    "            img = np.random.rand(img_size, img_size, 3)\n",
    "            if class_name == 'plastic':\n",
    "                img[:, :, 0] += 0.5  # More red\n",
    "            elif class_name == 'paper':\n",
    "                img[:, :, 1] += 0.5  # More green  \n",
    "            elif class_name == 'glass':\n",
    "                img[:, :, 2] += 0.5  # More blue\n",
    "            elif class_name == 'metal':\n",
    "                img += 0.3  # Brighter\n",
    "            else:  # organic\n",
    "                img[:, :, 0] += 0.3\n",
    "                img[:, :, 1] += 0.3\n",
    "            \n",
    "            img = np.clip(img, 0, 1)\n",
    "            X_train.append(img)\n",
    "            y_train.append(class_id)\n",
    "        \n",
    "        # Test samples (20% of training)\n",
    "        for i in range(samples_per_class // 5):\n",
    "            img = np.random.rand(img_size, img_size, 3)\n",
    "            if class_name == 'plastic':\n",
    "                img[:, :, 0] += 0.5\n",
    "            elif class_name == 'paper':\n",
    "                img[:, :, 1] += 0.5\n",
    "            elif class_name == 'glass':\n",
    "                img[:, :, 2] += 0.5\n",
    "            elif class_name == 'metal':\n",
    "                img += 0.3\n",
    "            else:  # organic\n",
    "                img[:, :, 0] += 0.3\n",
    "                img[:, :, 1] += 0.3\n",
    "            \n",
    "            img = np.clip(img, 0, 1)\n",
    "            X_test.append(img)\n",
    "            y_test.append(class_id)\n",
    "    \n",
    "    return np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "\n",
    "# Create dataset\n",
    "X_train, y_train, X_test, y_test = create_simple_dataset()\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Image size: {X_train[0].shape}\")\n",
    "print(f\"Classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c19dc-d795-4be3-b62e-b1f3d507cd30",
   "metadata": {},
   "source": [
    "## Build Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d2cf795-a3c5-42f5-8efd-52ca10e16d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building simple model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created!\n",
      "Model parameters: 822,597\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBuilding simple model...\")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=X_train[0].shape),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model created!\")\n",
    "print(f\"Model parameters: {model.count_params():,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d9e78-db75-41fd-bd50-6879a577583d",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5fc4774-4230-4359-b39b-33fec36597cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model...\n",
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.2143 - loss: 1.8397 - val_accuracy: 0.4000 - val_loss: 1.3480\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.4145 - loss: 1.2286 - val_accuracy: 0.8000 - val_loss: 0.7559\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.8034 - loss: 0.6548 - val_accuracy: 1.0000 - val_loss: 0.2643\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.2383 - val_accuracy: 1.0000 - val_loss: 0.0678\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0459 - val_accuracy: 1.0000 - val_loss: 0.0104\n",
      "Epoch 6/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 7/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 9.9125e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 8.5268e-04 - val_accuracy: 1.0000 - val_loss: 6.9397e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 5.6987e-04 - val_accuracy: 1.0000 - val_loss: 4.4486e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 3.7224e-04 - val_accuracy: 1.0000 - val_loss: 3.3673e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 2.8773e-04 - val_accuracy: 1.0000 - val_loss: 2.7029e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 2.3443e-04 - val_accuracy: 1.0000 - val_loss: 2.2682e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 1.9847e-04 - val_accuracy: 1.0000 - val_loss: 1.9636e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 1.7334e-04 - val_accuracy: 1.0000 - val_loss: 1.7433e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 1.5366e-04 - val_accuracy: 1.0000 - val_loss: 1.5687e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 1.3757e-04 - val_accuracy: 1.0000 - val_loss: 1.4154e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 1.2389e-04 - val_accuracy: 1.0000 - val_loss: 1.2822e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 1.1200e-04 - val_accuracy: 1.0000 - val_loss: 1.1663e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 1.0156e-04 - val_accuracy: 1.0000 - val_loss: 1.0630e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 9.2520e-05 - val_accuracy: 1.0000 - val_loss: 9.7340e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining model...\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,  # Quick training\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb6f23f-730a-40f6-a15b-aaba252be12e",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08d2925a-88c9-418c-bd60-61281ac4c6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model...\n",
      "Test Accuracy: 1.000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     plastic       1.00      1.00      1.00        10\n",
      "       paper       1.00      1.00      1.00        10\n",
      "       glass       1.00      1.00      1.00        10\n",
      "       metal       1.00      1.00      1.00        10\n",
      "     organic       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nEvaluating model...\")\n",
    "\n",
    "# Test accuracy\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
    "\n",
    "# Predictions\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predicted_classes, target_names=class_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d19b0f-9715-4cb6-af56-4aa4cab46d55",
   "metadata": {},
   "source": [
    "## Convert to TensorFlow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "316f766c-3620-47b2-abbe-23544494a32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting to TensorFlow Lite...\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\USER\\AppData\\Local\\Temp\\tmpovwo14a3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\USER\\AppData\\Local\\Temp\\tmpovwo14a3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\USER\\AppData\\Local\\Temp\\tmpovwo14a3'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2431128962144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2431128532976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2431128968480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2431128967072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2431128964608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2431128962320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2431128969712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2431128969008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "TensorFlow Lite model saved: recyclable_classifier.tflite\n",
      "Model size: 812.0 KB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConverting to TensorFlow Lite...\")\n",
    "\n",
    "# Convert model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save TensorFlow Lite model\n",
    "tflite_path = 'recyclable_classifier.tflite'\n",
    "with open(tflite_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TensorFlow Lite model saved: {tflite_path}\")\n",
    "print(f\"Model size: {len(tflite_model) / 1024:.1f} KB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b288b3-b277-4713-a131-56492f0a2e23",
   "metadata": {},
   "source": [
    "## Test TensorFlow Lite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b95c8b0-aade-4d13-af0f-5dbcac8e70d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing TensorFlow Lite model...\n",
      "TensorFlow Lite Accuracy: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting TensorFlow Lite model...\")\n",
    "\n",
    "# Load TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test on few samples\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(min(20, len(X_test))):\n",
    "    # Prepare input\n",
    "    input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n",
    "    \n",
    "    # Run inference\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Get result\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    predicted = np.argmax(output_data)\n",
    "    \n",
    "    if predicted == y_test[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "tflite_accuracy = correct / total\n",
    "print(f\"TensorFlow Lite Accuracy: {tflite_accuracy:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae74ced4-696b-45cc-813d-96fa39d6bf5c",
   "metadata": {},
   "source": [
    "## Measure Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d61b197-8a4d-4bf2-b9e8-e3c8af993181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Measuring inference speed...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "Original model: 20.7 ms per image\n",
      "TensorFlow Lite: 1.9 ms per image\n",
      "Speed improvement: 11.1x faster\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMeasuring inference speed...\")\n",
    "\n",
    "# Test original model speed\n",
    "start_time = time.time()\n",
    "_ = model.predict(X_test[:10])\n",
    "original_time = (time.time() - start_time) / 10\n",
    "\n",
    "# Test TensorFlow Lite speed\n",
    "start_time = time.time()\n",
    "for i in range(10):\n",
    "    input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    _ = interpreter.get_tensor(output_details[0]['index'])\n",
    "tflite_time = (time.time() - start_time) / 10\n",
    "\n",
    "print(f\"Original model: {original_time*1000:.1f} ms per image\")\n",
    "print(f\"TensorFlow Lite: {tflite_time*1000:.1f} ms per image\")\n",
    "print(f\"Speed improvement: {original_time/tflite_time:.1f}x faster\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d0ba60-e51c-47cd-84e5-00833f961797",
   "metadata": {},
   "source": [
    "## Simple Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e84d5103-dda2-4cef-8dce-c0f3fafa28c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EDGE AI RECYCLABLE CLASSIFIER - RESULTS\n",
      "==================================================\n",
      "Model Accuracy: 100.0%\n",
      "TensorFlow Lite Accuracy: 100.0%\n",
      "Model Size: 812.0 KB\n",
      "Inference Speed: 1.9 ms per image\n",
      "Classes: plastic, paper, glass, metal, organic\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EDGE AI RECYCLABLE CLASSIFIER - RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Model Accuracy: {test_accuracy:.1%}\")\n",
    "print(f\"TensorFlow Lite Accuracy: {tflite_accuracy:.1%}\")\n",
    "print(f\"Model Size: {len(tflite_model)/1024:.1f} KB\")\n",
    "print(f\"Inference Speed: {tflite_time*1000:.1f} ms per image\")\n",
    "print(f\"Classes: {', '.join(class_names)}\")\n",
    "print(\"=\"*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580a650d-b1af-4775-a0c3-cc3c2fd88336",
   "metadata": {},
   "source": [
    "## Edge AI Benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7823773-818d-4129-8c46-4e1e829b7389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EDGE AI BENEFITS FOR REAL-TIME APPLICATIONS:\n",
      "1. FAST: Only 1.9 ms per classification\n",
      "2. SMALL: Only 812.0 KB model size\n",
      "3. OFFLINE: Works without internet\n",
      "4. PRIVATE: Data stays on device\n",
      "5. CHEAP: No cloud costs\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEDGE AI BENEFITS FOR REAL-TIME APPLICATIONS:\")\n",
    "print(\"1. FAST: Only\", f\"{tflite_time*1000:.1f} ms\", \"per classification\")\n",
    "print(\"2. SMALL: Only\", f\"{len(tflite_model)/1024:.1f} KB\", \"model size\")\n",
    "print(\"3. OFFLINE: Works without internet\")\n",
    "print(\"4. PRIVATE: Data stays on device\")\n",
    "print(\"5. CHEAP: No cloud costs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fe10f0-bf38-4f8f-aada-6301079d7a6e",
   "metadata": {},
   "source": [
    "## Simple Deployment Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ee44ed2-a8bc-4377-a592-ccfb0ccf9f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deployment code saved: raspberry_pi_deploy.py\n"
     ]
    }
   ],
   "source": [
    "deployment_code = '''\n",
    "# Simple Raspberry Pi Deployment Code\n",
    "# Save as: raspberry_pi_deploy.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load the model\n",
    "interpreter = tf.lite.Interpreter(model_path='recyclable_classifier.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "class_names = ['plastic', 'paper', 'glass', 'metal', 'organic']\n",
    "\n",
    "def classify_image(image_path):\n",
    "    # Load and preprocess image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    # Run inference\n",
    "    interpreter.set_tensor(input_details[0]['index'], image)\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Get result\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])\n",
    "    predicted_class = np.argmax(output)\n",
    "    confidence = np.max(output)\n",
    "    \n",
    "    return class_names[predicted_class], confidence\n",
    "\n",
    "# Example usage:\n",
    "# result, confidence = classify_image('recyclable_item.jpg')\n",
    "# print(f\"This is {result} with {confidence:.2f} confidence\")\n",
    "'''\n",
    "\n",
    "with open('raspberry_pi_deploy.py', 'w') as f:\n",
    "    f.write(deployment_code)\n",
    "\n",
    "print(\"\\nDeployment code saved: raspberry_pi_deploy.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f072a304-2056-4e42-9f20-f3d28a893551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606c84bd-c702-4caa-85d8-b31a4ae697bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f69f40-2eb1-49a5-b627-28b2f869bfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2392dd0b-d90b-4053-b6b4-a96818525ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd128a1-c744-4152-9afb-54a2b82dedca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb22c9d-9f65-40d6-9531-886820f4d702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b04b092-c329-4d78-958c-4f6ab806758a",
   "metadata": {},
   "source": [
    "### Show Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef58878-c953-4206-8aab-7ecc87311d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSample Predictions:\")\n",
    "for i in range(5):\n",
    "    actual = class_names[y_test[i]]\n",
    "    predicted = class_names[predicted_classes[i]]\n",
    "    confidence = np.max(predictions[i])\n",
    "    print(f\"Sample {i+1}: Actual={actual}, Predicted={predicted}, Confidence={confidence:.2f}\")\n",
    "\n",
    "print(\"\\n✅ ALL DONE! Your Edge AI model is ready for deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
